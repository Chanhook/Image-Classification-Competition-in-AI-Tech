{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8680a9ba-aee1-4134-9e6a-da231fc222ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -n base -c conda-forge jupyterlab_widgets -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f555b0e-6c63-4e49-8cf5-a68e3b4e7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7e8471-9e21-4eb6-b9a5-40a144260c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2021\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = True  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0588e7-5b2f-478d-88a2-d89bcb43fc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19226b9-9a44-4749-8d7e-f64cda093c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05d634aa-a785-4b4a-ae74-55a91df3b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_dataset(data):\n",
    "    \n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    \n",
    "    for i in range(len(data.classes)):\n",
    "        all_idx = []\n",
    "        \n",
    "        for j in tqdm(range(len(data))):\n",
    "            if i == data[j][1]:\n",
    "                all_idx.append(j)\n",
    "        \n",
    "        split_idx = int(len(all_idx) * 0.8)\n",
    "        \n",
    "        train_idx = np.concatenate((train_idx, all_idx[:split_idx]))\n",
    "        val_idx = np.concatenate((val_idx, all_idx[split_idx:]))\n",
    "    \n",
    "    datas = {}\n",
    "    datas['train'] = Subset(data, list(map(int, train_idx)))\n",
    "    datas['val'] = Subset(data, list(map(int, val_idx)))\n",
    "    \n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d31a7263-b6c3-410a-91db-6164b144dee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef train_val_dataset(data, val_split=0.2):\\n    train_idx, val_idx = train_test_split(list(range(len(data))), test_size=val_split, shuffle=False)\\n    datas = {}\\n    datas['train'] = Subset(data, train_idx)\\n    datas['val'] = Subset(data, val_idx)\\n    return datas\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def train_val_dataset(data, val_split=0.2):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(data))), test_size=val_split, shuffle=False)\n",
    "    datas = {}\n",
    "    datas['train'] = Subset(data, train_idx)\n",
    "    datas['val'] = Subset(data, val_idx)\n",
    "    return datas\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "663cc461-4515-4a66-a5b7-edd39a3e3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d037b207-527a-439c-85ba-97179dd1ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/cropped_v2.1/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512a951a-7d15-4c64-9d12-a4d302963fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run(target, sub_df, test_dir):\n",
    "    data_dir = f'/opt/ml/input/cropped_v2.1/train/images_classified_{target}/'\n",
    "    \n",
    "    dataset = datasets.ImageFolder(os.path.join(data_dir), transforms)\n",
    "    \n",
    "    print(f'*****{target}*****')\n",
    "    print(dataset)\n",
    "    print()\n",
    "    \n",
    "    class_names = dataset.classes\n",
    "    print(class_names)\n",
    "    print()\n",
    "    \n",
    "    print('****train, valid split****')\n",
    "    dataset_split = train_val_dataset(dataset)\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset_split['train'], batch_size=128, shuffle=True, num_workers=8)\n",
    "    valid_dataloader = torch.utils.data.DataLoader(dataset_split['val'], batch_size=128, shuffle=False, num_workers=8)\n",
    "    \n",
    "    model = models.resnet34(pretrained=True)\n",
    "\n",
    "    num_features = model.fc.in_features\n",
    "    # 전이 학습(transfer learning): 모델의 출력 뉴런 수를 18개로 교체하여 마지막 레이어 다시 학습\n",
    "    model.fc = nn.Linear(num_features, len(class_names)) \n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    num_epochs = 10\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 전체 반복(epoch) 수 만큼 반복하며\n",
    "    print('****start epoch****')\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "\n",
    "        # 배치 단위로 학습 데이터 불러오기\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 모델에 입력(forward)하고 결과 계산\n",
    "            optimizer.zero_grad() # 전체 grad 값을 초기화.\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset_split['train'])\n",
    "        epoch_acc = running_corrects / len(dataset_split['train']) * 100.\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        \n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in valid_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "                all_labels.extend(labels.data.cpu().numpy())\n",
    "        \n",
    "            valid_epoch_loss = running_loss / len(dataset_split['val'])\n",
    "            valid_epoch_acc = running_corrects / len(dataset_split['val']) * 100.\n",
    "            F1_score = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        # 학습 과정 중에 결과 출력\n",
    "        print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "        print(f'Valid Loss: {valid_epoch_loss:.4f} Valid Acc: {valid_epoch_acc:.4f} F1 Score: {F1_score:.4f}')\n",
    "    '''\n",
    "    valid_dataloader = torch.utils.data.DataLoader(dataset_split['val'], batch_size=128, shuffle=False, num_workers=8)\n",
    "    \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in valid_dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "        \n",
    "            all_labels.extend(labels.data.cpu().numpy())\n",
    "        \n",
    "            \n",
    "            # 한 배치의 첫 번째 이미지에 대하여 결과 시각화\n",
    "            print(f'[예측 결과: {class_names[preds[0]]}] (실제 정답: {class_names[labels.data[0]]})')\n",
    "            imshow(inputs.cpu().data[0], title='예측 결과: ' + class_names[preds[0]])\n",
    "            \n",
    "            \n",
    "        epoch_loss = running_loss / len(dataset_split['val'])\n",
    "        epoch_acc = running_corrects / len(dataset_split['val']) * 100.\n",
    "        print('[Test Phase] Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch_loss, epoch_acc, time.time() - start_time))\n",
    "    \n",
    "    F1_score = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    print(f'*****F1 Score: {F1_score}*****')\n",
    "    '''\n",
    "    image_dir = os.path.join(test_dir, 'images')\n",
    "    \n",
    "    image_paths = [os.path.join(image_dir, img_id) for img_id in sub_df.ImageID]\n",
    "    \n",
    "    test_set = TestDataset(image_paths, transforms)\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=8)\n",
    "    \n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "    \n",
    "    all_predictions2 = []\n",
    "\n",
    "    for p in all_predictions:\n",
    "        all_predictions2.append(class_names[p])\n",
    "        \n",
    "    sub_df[target] = all_predictions2\n",
    "    \n",
    "    return sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73b7e3f5-7c00-4b34-8fe5-a665d0e24fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/18900 [00:00<02:56, 107.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****mask*****\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 18900\n",
      "    Root location: /opt/ml/input/cropped_v2.1/train/images_classified_mask/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "\n",
      "['0', '12', '6']\n",
      "\n",
      "****train, valid split****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18900/18900 [00:56<00:00, 333.41it/s]\n",
      "100%|██████████| 18900/18900 [00:56<00:00, 333.57it/s]\n",
      "100%|██████████| 18900/18900 [00:56<00:00, 331.90it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****start epoch****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:28<00:00,  4.21it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.1675 Acc: 93.7963% Time: 31.8786s\n",
      "Valid Loss: 0.04938751205250069 Valid Acc: 98.17459869384766 F1 Score: 0.9701491161397802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.31it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Loss: 0.0138 Acc: 99.6230% Time: 63.0363s\n",
      "Valid Loss: 0.024944811377418104 Valid Acc: 99.10053253173828 F1 Score: 0.9853601176989547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.33it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2 Loss: 0.0050 Acc: 99.8876% Time: 94.2185s\n",
      "Valid Loss: 0.012671514553210092 Valid Acc: 99.60317993164062 F1 Score: 0.9933975200348962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.27it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3 Loss: 0.0028 Acc: 99.9273% Time: 125.5516s\n",
      "Valid Loss: 0.03460362219188865 Valid Acc: 98.94180297851562 F1 Score: 0.9837419693606003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.26it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4 Loss: 0.0015 Acc: 99.9537% Time: 157.1026s\n",
      "Valid Loss: 0.02396445334362354 Valid Acc: 99.23280334472656 F1 Score: 0.9877913858388118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.26it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5 Loss: 0.0005 Acc: 99.9934% Time: 188.6908s\n",
      "Valid Loss: 0.012563167029693624 Valid Acc: 99.62963104248047 F1 Score: 0.9937761086696605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.27it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6 Loss: 0.0002 Acc: 100.0000% Time: 220.1334s\n",
      "Valid Loss: 0.014578369163437476 Valid Acc: 99.57672119140625 F1 Score: 0.9930183580714823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.33it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#7 Loss: 0.0001 Acc: 100.0000% Time: 251.2650s\n",
      "Valid Loss: 0.01439959954900948 Valid Acc: 99.60317993164062 F1 Score: 0.9933975200348962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.27it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#8 Loss: 0.0001 Acc: 100.0000% Time: 282.8045s\n",
      "Valid Loss: 0.013314268926698123 Valid Acc: 99.62963104248047 F1 Score: 0.9937761086696605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.29it/s]\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#9 Loss: 0.0001 Acc: 100.0000% Time: 314.1588s\n",
      "Valid Loss: 0.01433407745675785 Valid Acc: 99.60317993164062 F1 Score: 0.9933975200348962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:09<00:00, 10.83it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = model_run('mask', submission, test_dir).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "853c105e-900e-4914-b628-1ec254c38388",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/18900 [00:00<00:56, 333.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****gender*****\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 18900\n",
      "    Root location: /opt/ml/input/cropped_v2.1/train/images_classified_gender/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "\n",
      "['0', '3']\n",
      "\n",
      "****train, valid split****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18900/18900 [00:57<00:00, 330.67it/s]\n",
      "100%|██████████| 18900/18900 [00:57<00:00, 327.54it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****start epoch****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:28<00:00,  4.25it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.2090 Acc: 91.5537% Time: 31.4276s\n",
      "Valid Loss: 0.09345550277275057 Valid Acc: 97.14361572265625 F1 Score: 0.9697486656307006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.29it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Loss: 0.0487 Acc: 98.3597% Time: 62.5849s\n",
      "Valid Loss: 0.24537892599465855 Valid Acc: 90.18778228759766 F1 Score: 0.8907644535987742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.28it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2 Loss: 0.0237 Acc: 99.2129% Time: 93.9504s\n",
      "Valid Loss: 0.1140575763192821 Valid Acc: 96.32373046875 F1 Score: 0.9608590296050512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.31it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3 Loss: 0.0039 Acc: 99.9206% Time: 124.8230s\n",
      "Valid Loss: 0.08510232664682066 Valid Acc: 97.5138931274414 F1 Score: 0.9739023713982433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.34it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4 Loss: 0.0011 Acc: 99.9868% Time: 155.5929s\n",
      "Valid Loss: 0.09832638301191486 Valid Acc: 97.38164520263672 F1 Score: 0.9723949407207202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.26it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5 Loss: 0.0004 Acc: 100.0000% Time: 186.8870s\n",
      "Valid Loss: 0.09959314730055946 Valid Acc: 97.46099090576172 F1 Score: 0.9732415987808567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.33it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6 Loss: 0.0002 Acc: 100.0000% Time: 217.9572s\n",
      "Valid Loss: 0.102018944617931 Valid Acc: 97.59323120117188 F1 Score: 0.9746256525816722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.31it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#7 Loss: 0.0001 Acc: 100.0000% Time: 249.1100s\n",
      "Valid Loss: 0.10593025400178273 Valid Acc: 97.5138931274414 F1 Score: 0.9737658011641207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.32it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#8 Loss: 0.0001 Acc: 100.0000% Time: 280.0284s\n",
      "Valid Loss: 0.10552384362529393 Valid Acc: 97.54033660888672 F1 Score: 0.9740679746164341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.36it/s]\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#9 Loss: 0.0001 Acc: 100.0000% Time: 310.7987s\n",
      "Valid Loss: 0.10835693556879653 Valid Acc: 97.56678009033203 F1 Score: 0.9743305238387885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:09<00:00, 10.52it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = model_run('gender', submission, test_dir).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb4e4f2-73fb-417a-84e8-2744a3fd4496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/18900 [00:00<02:18, 136.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****age*****\n",
      "Dataset ImageFolder\n",
      "    Number of datapoints: 18900\n",
      "    Root location: /opt/ml/input/cropped_v2.1/train/images_classified_age/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "\n",
      "['0', '1', '2']\n",
      "\n",
      "****train, valid split****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18900/18900 [00:57<00:00, 328.68it/s]\n",
      "100%|██████████| 18900/18900 [00:57<00:00, 328.93it/s]\n",
      "100%|██████████| 18900/18900 [00:57<00:00, 328.72it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****start epoch****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:28<00:00,  4.23it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.3510 Acc: 86.2094% Time: 31.7207s\n",
      "Valid Loss: 0.4834965151852636 Valid Acc: 82.35916137695312 F1 Score: 0.6464249203652348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.32it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Loss: 0.1826 Acc: 93.2138% Time: 62.6200s\n",
      "Valid Loss: 0.37551701485054484 Valid Acc: 85.40068817138672 F1 Score: 0.7530800164100007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.32it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2 Loss: 0.1186 Acc: 95.3238% Time: 93.7456s\n",
      "Valid Loss: 1.145969100380245 Valid Acc: 71.64771270751953 F1 Score: 0.6278183500929594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.29it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3 Loss: 0.0628 Acc: 97.6652% Time: 125.0251s\n",
      "Valid Loss: 0.8173257976094755 Valid Acc: 81.53927612304688 F1 Score: 0.713242641709714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.28it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4 Loss: 0.0291 Acc: 99.0277% Time: 156.4243s\n",
      "Valid Loss: 1.5521928255411412 Valid Acc: 73.2345962524414 F1 Score: 0.6548322991133234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.30it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5 Loss: 0.0172 Acc: 99.4973% Time: 187.5138s\n",
      "Valid Loss: 1.465400308268669 Valid Acc: 75.53556823730469 F1 Score: 0.6738135693539937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.29it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6 Loss: 0.0422 Acc: 98.4986% Time: 218.8241s\n",
      "Valid Loss: 1.0410242339739355 Valid Acc: 81.08966064453125 F1 Score: 0.7163802974085454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.35it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#7 Loss: 0.0023 Acc: 99.9735% Time: 249.5428s\n",
      "Valid Loss: 1.1183644257606327 Valid Acc: 83.12615966796875 F1 Score: 0.7266913411265054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.35it/s]\n",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#8 Loss: 0.0009 Acc: 99.9934% Time: 280.4103s\n",
      "Valid Loss: 1.0241032073552045 Valid Acc: 84.47501373291016 F1 Score: 0.7345442875403673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:27<00:00,  4.34it/s]\n",
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#9 Loss: 0.0004 Acc: 100.0000% Time: 311.1435s\n",
      "Valid Loss: 1.1406005663536027 Valid Acc: 84.05184173583984 F1 Score: 0.7299647900211793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:09<00:00, 10.63it/s]\n"
     ]
    }
   ],
   "source": [
    "submission = model_run('age', submission, test_dir).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6544f093-7973-4c0d-89b8-3a0c0379dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.astype({'age':'int','gender':'int','mask':'int'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70c7513e-892a-4bf0-b520-224b5421620a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageID</th>\n",
       "      <th>ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbc5c6e168e63498590db46022617123f1fe1268.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0e72482bf56b3581c081f7da2a6180b8792c7089.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b549040c49190cedc41327748aeb197c1670f14d.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>d71d4570505d6af8f777690e63edfa8d85ea4476.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>6cf1300e8e218716728d5820c0bab553306c2cfd.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>8140edbba31c3a824e817e6d5fb95343199e2387.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12598</th>\n",
       "      <td>030d439efe6fb5a7bafda45a393fc19f2bf57f54.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>f1e0b9594ae9f72571f0a9dc67406ad41f2edab0.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ImageID  ans\n",
       "0      cbc5c6e168e63498590db46022617123f1fe1268.jpg   13\n",
       "1      0e72482bf56b3581c081f7da2a6180b8792c7089.jpg    2\n",
       "2      b549040c49190cedc41327748aeb197c1670f14d.jpg   13\n",
       "3      4f9cb2a045c6d5b9e50ad3459ea7b791eb6e18bc.jpg   13\n",
       "4      248428d9a4a5b6229a7081c32851b90cb8d38d0c.jpg   12\n",
       "...                                             ...  ...\n",
       "12595  d71d4570505d6af8f777690e63edfa8d85ea4476.jpg    2\n",
       "12596  6cf1300e8e218716728d5820c0bab553306c2cfd.jpg    4\n",
       "12597  8140edbba31c3a824e817e6d5fb95343199e2387.jpg    9\n",
       "12598  030d439efe6fb5a7bafda45a393fc19f2bf57f54.jpg    1\n",
       "12599  f1e0b9594ae9f72571f0a9dc67406ad41f2edab0.jpg    7\n",
       "\n",
       "[12600 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try : submission['ans'] = submission['mask'] + submission['gender'] + submission['age'] ; submission2 = submission.drop(['mask','gender','age'],axis=1)\n",
    "except : pass\n",
    "submission2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10f6790e-3883-4d9f-ba8b-1a818d4bdb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2.to_csv(os.path.join(test_dir, 'submission.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd0d0d-079b-4f1f-9762-1ae7372cfc30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
