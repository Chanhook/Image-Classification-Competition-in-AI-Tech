{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "8680a9ba-aee1-4134-9e6a-da231fc222ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -n base -c conda-forge jupyterlab_widgets -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "3f555b0e-6c63-4e49-8cf5-a68e3b4e7674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c7e8471-9e21-4eb6-b9a5-40a144260c86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device 객체\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2021\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)  # type: ignore\n",
    "torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "torch.backends.cudnn.benchmark = False  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0588e7-5b2f-478d-88a2-d89bcb43fc4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d19226b9-9a44-4749-8d7e-f64cda093c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋을 불러올 때 사용할 변형(transformation) 객체 정의\n",
    "transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 248)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomAffine((20)),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # 정규화(normalization)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d634aa-a785-4b4a-ae74-55a91df3b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_dataset(data):\n",
    "    \n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    \n",
    "    for i in range(len(data.classes)):\n",
    "        all_idx = []\n",
    "        \n",
    "        for j in tqdm(range(len(data))):\n",
    "#         for j in range(len(data)):\n",
    "            if i == data[j][1]:\n",
    "                all_idx.append(j)\n",
    "        \n",
    "        split_idx = int(len(all_idx) * 0.9)\n",
    "        \n",
    "        train_idx = np.concatenate((train_idx, all_idx[:split_idx]))\n",
    "        val_idx = np.concatenate((val_idx, all_idx[split_idx:]))\n",
    "    \n",
    "    datas = {}\n",
    "    datas['train'] = Subset(data, list(map(int, train_idx)))\n",
    "    datas['val'] = Subset(data, list(map(int, val_idx)))\n",
    "    \n",
    "    return datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d31a7263-b6c3-410a-91db-6164b144dee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef train_val_dataset(data, val_split=0.2):\\n    train_idx, val_idx = train_test_split(list(range(len(data))), test_size=val_split, shuffle=False)\\n    datas = {}\\n    datas['train'] = Subset(data, train_idx)\\n    datas['val'] = Subset(data, val_idx)\\n    return datas\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def train_val_dataset(data, val_split=0.2):\n",
    "    train_idx, val_idx = train_test_split(list(range(len(data))), test_size=val_split, shuffle=False)\n",
    "    datas = {}\n",
    "    datas['train'] = Subset(data, train_idx)\n",
    "    datas['val'] = Subset(data, val_idx)\n",
    "    return datas\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "663cc461-4515-4a66-a5b7-edd39a3e3f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_paths, transform):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d037b207-527a-439c-85ba-97179dd1ab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '/opt/ml/input/cropped_v2/eval'\n",
    "submission = pd.read_csv(os.path.join(test_dir, 'info.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "7898063e-4dc5-4eb7-b070-b9bb377b191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets.ImageFolder(os.path.join(f'/opt/ml/input/cropped_v2/train/images_classified_age/'), transforms)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "512a951a-7d15-4c64-9d12-a4d302963fe7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_run(target, sub_df, test_dir):\n",
    "    data_dir = f'/opt/ml/input/cropped_v2/train/images_classified_{target}/'\n",
    "    \n",
    "    dataset = datasets.ImageFolder(os.path.join(data_dir), transforms)\n",
    "    \n",
    "    print(f'*****{target}*****')\n",
    "    print(dataset)\n",
    "    print()\n",
    "    \n",
    "    class_names = dataset.classes\n",
    "    print(class_names)\n",
    "    print()\n",
    "    \n",
    "    print('****train, valid split****')\n",
    "    dataset_split = train_val_dataset(dataset)\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(dataset_split['train'], batch_size=128, shuffle=True, num_workers=8)\n",
    "    valid_dataloader = torch.utils.data.DataLoader(dataset_split['val'], batch_size=128, shuffle=False, num_workers=8)\n",
    "    \n",
    "    model = models.resnet34(pretrained=True)\n",
    "\n",
    "    num_features = model.fc.in_features\n",
    "    # 전이 학습(transfer learning): 모델의 출력 뉴런 수를 18개로 교체하여 마지막 레이어 다시 학습\n",
    "    model.fc = nn.Linear(num_features, len(class_names)) \n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    num_epochs = 3 if target=='mask' else 5\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 전체 반복(epoch) 수 만큼 반복하며\n",
    "    print('****start epoch****')\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        \n",
    "        if epoch == 2 and target=='age': optimizer = optim.SGD(model.parameters(), lr=0.0003, momentum=0.9)\n",
    "        \n",
    "        # 배치 단위로 학습 데이터 불러오기\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 모델에 입력(forward)하고 결과 계산\n",
    "            optimizer.zero_grad() # 전체 grad 값을 초기화.\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset_split['train'])\n",
    "        epoch_acc = running_corrects / len(dataset_split['train']) * 100.\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        \n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for inputs, labels in valid_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "                all_labels.extend(labels.data.cpu().numpy())\n",
    "        \n",
    "            valid_epoch_loss = running_loss / len(dataset_split['val'])\n",
    "            valid_epoch_acc = running_corrects / len(dataset_split['val']) * 100.\n",
    "            F1_score = f1_score(all_labels, all_preds, average='macro')\n",
    "            \n",
    "        # 학습 과정 중에 결과 출력\n",
    "        print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "        print(f'Valid Loss: {valid_epoch_loss:.4f} Valid Acc: {valid_epoch_acc:.4f} F1 Score: {F1_score:.4f}')\n",
    "        if F1_score > 0.77 and target == 'age' : break\n",
    "        \n",
    "    image_dir = os.path.join(test_dir, 'images')\n",
    "    \n",
    "    image_paths = [os.path.join(image_dir, img_id) for img_id in sub_df.ImageID]\n",
    "    \n",
    "    test_set = TestDataset(image_paths, transforms)\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=128, shuffle=False, num_workers=8)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    model.eval()\n",
    "    all_output = []        ###########################################################\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(test_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "        \n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_output.append(outputs)   #############################################\n",
    "    mask_soft = torch.nn.functional.softmax(torch.cat(all_output,dim=0),dim=1)  ######\n",
    "    for i in range(len(class_names)):  ###############################################\n",
    "        sub_df[class_names[i]] = mask_soft[:,i].cpu().numpy()  #######################\n",
    "    sub_df.to_csv(f'sub_{target}.csv')  ##############################################\n",
    "    all_predictions2 = []\n",
    "\n",
    "    for p in all_predictions:\n",
    "        all_predictions2.append(class_names[p])\n",
    "        \n",
    "    sub_df[target] = all_predictions2\n",
    "    torch.save(model.state_dict(), os.getcwd()+'/'+f'model_{target}')\n",
    "    return sub_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73b7e3f5-7c00-4b34-8fe5-a665d0e24fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26968/2995623967.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission_mask\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model_run' is not defined"
     ]
    }
   ],
   "source": [
    "submission_mask  = model_run('mask', submission, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3272c3e-9a17-4c3e-bbad-55ed1975ca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission_mask.drop(['0','12','6','.ipynb_checkpoints'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853c105e-900e-4914-b628-1ec254c38388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = model_run('gender', submission, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba5d858-ef34-4a3b-848d-b0cb593a0650",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission.drop(['0','3'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4804d-1a28-4831-bb84-24f79d2600df",
   "metadata": {},
   "source": [
    "## age 메타데이터 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e49c28-6e16-432b-b2cc-c4db1ae10133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = submission.astype({'gender':'int','mask':'int'})\n",
    "# submission.to_csv('submission_before_age.csv', index=False)\n",
    "submission = pd.read_csv('submission_before_age.csv')\n",
    "ground_best_F1_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27da1459-a20b-4f2e-a131-f00a99fb7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#age 예측을 위한 데이터셋\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "from typing import Any, Callable, cast, Dict, List, Optional, Tuple\n",
    "from torchvision.datasets.folder import default_loader, IMG_EXTENSIONS\n",
    "\n",
    "class TrainDatasetAge(ImageFolder):\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            loader: Callable[[str], Any] = default_loader,\n",
    "            is_valid_file: Optional[Callable[[str], bool]] = None,\n",
    "    ):\n",
    "        super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n",
    "                                          transform=transform,\n",
    "                                          target_transform=target_transform,\n",
    "                                          is_valid_file=is_valid_file)\n",
    "        self.imgs = self.samples\n",
    "        ##위는 그냥 기존 코드\n",
    "        ##아래는 직접 작성\n",
    "        gender_dic = {'male':0, 'female':3 }\n",
    "        mask_dic = {'mask':0, 'incor':6, 'norma':12} ##이는 전처리의 편의에 의함\n",
    "        def feature_extract(f):\n",
    "            ff = f[0].split('/')[-1].split('.')[0].replace('incorrect_mask','incorr').split('_')\n",
    "            return gender_dic[ff[1]], mask_dic[ff[-1][:-1]]\n",
    "        def feature_onehot(f):\n",
    "            return torch.tensor((int(f[0]==3),int(f[1]==0),int(f[1]==6),int(f[1]==12)))\n",
    "        def age(f):\n",
    "            ff = f[0].split('/')[-1].split('.')[0].replace('incorrect_mask','incorr').split('_')\n",
    "            return int(f)\n",
    "        self.features = list(map(feature_extract, self.samples))\n",
    "        self.features = list(map(feature_onehot, self.features))\n",
    "        self.age = list(map(feature_onehot, self.features))\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        #아래 한 줄과 리턴에 하나 추가\n",
    "        features = self.features[index]\n",
    "        age = self.age[index]\n",
    "        return sample, target, features, age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7353f2d-5d76-4fb7-bb04-e0d04ef9f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TestDatasetAge(Dataset):\n",
    "    def __init__(self, img_paths, transform, submission):\n",
    "        self.img_paths = img_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "        #순서가 같다는 전제. 아니면 다른 어려운 방법을 강구해야함.\n",
    "        self.gender = submission['gender']\n",
    "        self.mask = submission['mask']\n",
    "        self.features = [(submission['gender'][i],submission['mask'][i]) for i in range(len(self.gender))]\n",
    "        \n",
    "        def feature_onehot(f):\n",
    "            return torch.tensor((int(f[0]==3),int(f[1]==0),int(f[1]==6),int(f[1]==12))) \n",
    "        \n",
    "        self.features = list(map(feature_onehot, self.features))\n",
    "        \n",
    "    \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image) \n",
    "        features = self.features[index]\n",
    "        return image, features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18738764-152e-4c65-b3b7-3f0796bebf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timm\n",
    "# class AgeCustomModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.model = timm.create_model('swin_large_patch9_window12_224', pretrained=False, in_chans=3)\n",
    "#         self.model.head = nn.Linear(self.model.head.in_features, 128)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.dense1 = nn.Linear(516, 64) # 성별1 마스크 3으로 원핫 인코딩했기 때문에 4 추가\n",
    "#         self.dense2 = nn.Linear(64, 3)\n",
    "        \n",
    "#     def forward(self, image, features):\n",
    "#         x1 = self.model(image)\n",
    "#         x = self.dropout(x1)\n",
    "#         x = torch.cat([x, features], dim=1)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76a13dcf-9497-4448-87a9-3090a609cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeCustomModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, 128)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.Linear(132, 64) # 성별1 마스크 3으로 원핫 인코딩했기 때문에 4 추가\n",
    "        self.dense2 = nn.Linear(64, 3)\n",
    "        \n",
    "    def forward(self, image, features):\n",
    "        x1 = self.model(image)\n",
    "        x = self.dropout(x1)\n",
    "        x = torch.cat([x, features], dim=1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec58914e-6e73-4e3f-aa1f-a97374b040a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AgeCustomModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.model = models.resnet34(pretrained=True)\n",
    "#         in_features = self.model.fc.in_features\n",
    "#         self.model.fc = nn.Linear(in_features, 128)\n",
    "#         self.dropout = nn.Dropout(0.1)\n",
    "#         self.dense1 = nn.Linear(132, 64) # 성별1 마스크 3으로 원핫 인코딩했기 때문에 4 추가\n",
    "#         self.dense2 = nn.Linear(64, 1)\n",
    "        \n",
    "#     def forward(self, image, features):\n",
    "#         x1 = self.model(image)\n",
    "#         x = self.dropout(x1)\n",
    "#         x = torch.cat([x, features], dim=1)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "        \n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36087455-1ce1-4a0c-a9bd-d95a90496701",
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def forward(self, image, features, targets=None):\n",
    "#         x1 = self.model(image)\n",
    "#         x = self.dropout(x1)\n",
    "#         x = torch.cat([x, features], dim=1)\n",
    "#         x = self.dense1(x)\n",
    "#         x = self.dense2(x)\n",
    "        \n",
    "#         x = torch.cat([x, x1, features], dim=1)\n",
    "#         return x, 0, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c837733-e938-4c92-a11e-e9ed34de3ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 9/21588 [00:00<04:00, 89.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****age*****\n",
      "Dataset TrainDatasetAge\n",
      "    Number of datapoints: 21588\n",
      "    Root location: /opt/ml/input/cropped_v2/train/images_classified_age/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(224, 248), interpolation=PIL.Image.BILINEAR)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               RandomAffine(degrees=[-20.0, 20.0])\n",
      "               RandomRotation(degrees=[-20.0, 20.0], resample=False, expand=False)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "           )\n",
      "\n",
      "['0', '1', '2']\n",
      "\n",
      "****train, valid split****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21588/21588 [01:18<00:00, 275.63it/s]\n",
      "100%|██████████| 21588/21588 [01:17<00:00, 278.68it/s]\n",
      "100%|██████████| 21588/21588 [01:17<00:00, 277.48it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dir = f'/opt/ml/input/cropped_v2/train/images_classified_age/'\n",
    "\n",
    "dataset = TrainDatasetAge(os.path.join(data_dir), transforms)  ################################# 데이터셋 함수 변경\n",
    "\n",
    "print(f'*****age*****')\n",
    "print(dataset)\n",
    "print()\n",
    "\n",
    "class_names = dataset.classes\n",
    "print(class_names)\n",
    "print()\n",
    "\n",
    "print('****train, valid split****')\n",
    "dataset_split = train_val_dataset(dataset)\n",
    "dataloader = torch.utils.data.DataLoader(dataset_split['train'], batch_size=60, shuffle=True, num_workers=4,drop_last=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset_split['val'], batch_size=60, shuffle=False, num_workers=4,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9606e8a3-7e7d-4d6d-9c1c-4b957c227956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(valid_dataloader))[2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e38bda33-9a0e-4dc0-b709-4d587b64bcfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def age_model_run(sub_df, test_dir): #####target을 변수로 받지 않고 관련 부분들을 모두 수정 #########################\n",
    "    data_dir = f'/opt/ml/input/cropped_v2/train/images_classified_age/'\n",
    "\n",
    "    ################## 모델부분 코드 변경 #################\n",
    "    model = AgeCustomModel()\n",
    "    best_F1_score = 0 \n",
    "    #######################################################\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    num_epochs = 7\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 전체 반복(epoch) 수 만큼 반복하며\n",
    "    print('****start epoch****')\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.\n",
    "        running_corrects = 0\n",
    "        \n",
    "#         if epoch == 3: optimizer = optim.SGD(model.parameters(), lr=0.0005, momentum=0.3)\n",
    "#         if epoch == 5: optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.3)\n",
    "#         if epoch == 6: optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.3)\n",
    "            \n",
    "        # 배치 단위로 학습 데이터 불러오기                                ##################features 활용하는 부분 추가\n",
    "#         for inputs, labels in tqdm(dataloader):\n",
    "        for inputs, labels, features, _ in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            features = features.to(device)##################features 활용하는 부분 추가\n",
    "\n",
    "            # 모델에 입력(forward)하고 결과 계산\n",
    "            optimizer.zero_grad() # 전체 grad 값을 초기화.\n",
    "#             outputs = model(inputs)\n",
    "            outputs = model(inputs,features) #안되면 model.forward로 바꿔보기\n",
    "    \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / len(dataset_split['train'])\n",
    "        epoch_acc = running_corrects / len(dataset_split['train']) * 100.\n",
    "        \n",
    "        # validation\n",
    "        model.eval()\n",
    "        \n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            running_loss = 0.\n",
    "            running_corrects = 0\n",
    "            \n",
    "#             for inputs, labels in valid_dataloader:\n",
    "            for inputs, labels, features, _ in valid_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                features = features.to(device)##################features 활용하는 부분 추가\n",
    "            \n",
    "#                 outputs = model(inputs)\n",
    "                outputs = model(inputs,features)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "                all_labels.extend(labels.data.cpu().numpy())\n",
    "        \n",
    "            valid_epoch_loss = running_loss / len(dataset_split['val'])\n",
    "            valid_epoch_acc = running_corrects / len(dataset_split['val']) * 100.\n",
    "            F1_score = f1_score(all_labels, all_preds, average='macro')\n",
    "            \n",
    "        # 학습 과정 중에 결과 출력\n",
    "        print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "        print(f'Valid Loss: {valid_epoch_loss:.4f} Valid Acc: {valid_epoch_acc:.4f} F1 Score: {F1_score:.4f}')\n",
    "#         if F1_score > 0.77 and target == 'age' : break\n",
    "        if F1_score > best_F1_score : best_F1_score, best_model = F1_score, copy.deepcopy(model)   ############최고모델 활용을 위한 코드 추가\n",
    "        print('best_F1_score : ',best_F1_score) ############최고모델 활용을 위한 코드 추가\n",
    "        \n",
    "    if ground_best_F1_score < best_F1_score : ############최고모델 활용을 위한 코드 추가\n",
    "        print(f\"ground_best_F1_score갱신! {ground_best_F1_score} -> {best_F1_score}\")\n",
    "        now = datetime.datetime.now()\n",
    "        nowDatetime = now.strftime('%Y_%m%d_%H%M')\n",
    "        torch.save(best_model.state_dict(), os.getcwd()+'/'+f'model_age_{nowDatetime}') ############최고모델 활용을 위한 코드 추가\n",
    "        \n",
    "        \n",
    "    image_dir = os.path.join(test_dir, 'images')\n",
    "    \n",
    "    image_paths = [os.path.join(image_dir, img_id) for img_id in sub_df.ImageID]\n",
    "    \n",
    "    test_set = TestDatasetAge(image_paths, transforms, submission)  ###################################데이터셋 변경\n",
    "    \n",
    "    test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=4)\n",
    "    \n",
    "    all_predictions = []\n",
    "\n",
    "    best_model.eval()\n",
    "    all_output = []        ###########################################################\n",
    "    with torch.no_grad():\n",
    "#         for inputs in tqdm(test_dataloader):\n",
    "\n",
    "        for inputs, features in tqdm(test_dataloader):\n",
    "\n",
    "            inputs = inputs.to(device) \n",
    "            features = features.to(device) ##################features 활용하는 부분 추가\n",
    "            \n",
    "#             outputs = model(inputs)\n",
    "            outputs = best_model(inputs,features)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "            all_output.append(outputs)   #############################################\n",
    "    mask_soft = torch.nn.functional.softmax(torch.cat(all_output,dim=0),dim=1)  ######\n",
    "    for i in range(len(class_names)):  ###############################################\n",
    "        sub_df[class_names[i]] = mask_soft[:,i].cpu().numpy()  #######################\n",
    "    sub_df.to_csv(f'sub_age.csv')  ###################################################\n",
    "    all_predictions2 = []\n",
    "\n",
    "    for p in all_predictions:\n",
    "        all_predictions2.append(class_names[p])\n",
    "        \n",
    "    sub_df['age'] = all_predictions2\n",
    "    \n",
    "    return sub_df.copy(), max(ground_best_F1_score,best_F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7026906-de7d-4ea1-a132-810f722cf72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def trs(a):\n",
    "#     a1 = []\n",
    "#     for i in a:\n",
    "#         a1 = torch.Tensor()\n",
    "#         for j in i:\n",
    "#             if j < 30:\n",
    "#                 a1 = torch.cat([a1, torch.tensor([[1,0,0]])],dim=0)\n",
    "#             elif j <59:\n",
    "#                 a1 = torch.cat([a1, torch.tensor([[0,1,0]])],dim=0)\n",
    "#             else:\n",
    "#                 a1 = torch.cat([a1, torch.tensor([[0,0,1]])],dim=0)\n",
    "#         a2.append(a1)\n",
    "#     return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebf35f7e-9c87-4b46-bb05-6316962b7f51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def age_model_run(sub_df, test_dir): #####target을 변수로 받지 않고 관련 부분들을 모두 수정 #########################\n",
    "#     data_dir = f'/opt/ml/input/cropped_v2/train/images_classified_age/'\n",
    "\n",
    "#     ################## 모델부분 코드 변경 #################\n",
    "#     model = AgeCustomModel()\n",
    "#     best_F1_score = 0 \n",
    "#     #######################################################\n",
    "#     model = model.to(device)\n",
    "\n",
    "# #     criterion = nn.CrossEntropyLoss()\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# #     optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "#     num_epochs = 7\n",
    "#     model.train()\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # 전체 반복(epoch) 수 만큼 반복하며\n",
    "#     print('****start epoch****')\n",
    "#     for epoch in range(num_epochs):\n",
    "#         running_loss = 0.\n",
    "#         running_corrects = 0\n",
    "\n",
    "#         # 배치 단위로 학습 데이터 불러오기                                ##################features 활용하는 부분 추가\n",
    "# #         for inputs, labels in tqdm(dataloader):\n",
    "#         for inputs, _ , features, labels in tqdm(dataloader):\n",
    "#             inputs = inputs.unsqueeze(1).float().to(device)\n",
    "#             labels = labels.to(device)\n",
    "            \n",
    "#             features = features.to(device)##################features 활용하는 부분 추가\n",
    "\n",
    "#             # 모델에 입력(forward)하고 결과 계산\n",
    "#             optimizer.zero_grad() # 전체 grad 값을 초기화.\n",
    "# #             outputs = model(inputs)\n",
    "#             outputs = model(inputs,features) #안되면 model.forward로 바꿔보기\n",
    "    \n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "#             loss = criterion(outputs, labels)\n",
    "\n",
    "#             # 역전파를 통해 기울기(gradient) 계산 및 학습 진행\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "#         epoch_loss = running_loss / len(dataset_split['train'])\n",
    "#         epoch_acc = running_corrects / len(dataset_split['train']) * 100.\n",
    "        \n",
    "#         # validation\n",
    "#         model.eval()\n",
    "        \n",
    "#         all_labels = []\n",
    "#         all_preds = []\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             running_loss = 0.\n",
    "#             running_corrects = 0\n",
    "            \n",
    "# #             for inputs, labels in valid_dataloader:\n",
    "#             for inputs, labels, features, _ in valid_dataloader:\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 labels = labels.to(device)\n",
    "\n",
    "#                 features = features.to(device)##################features 활용하는 부분 추가\n",
    "            \n",
    "# #                 outputs = model(inputs)\n",
    "#                 outputs = model(inputs,features)\n",
    "#                 outputs = trs(outputs)\n",
    "#                 _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "#                 all_preds.extend(preds.cpu().numpy())\n",
    "        \n",
    "#                 loss = criterion(outputs, labels)\n",
    "\n",
    "#                 running_loss += loss.item() * inputs.size(0)\n",
    "#                 running_corrects += torch.sum(preds == labels.data)\n",
    "        \n",
    "#                 all_labels.extend(labels.data.cpu().numpy())\n",
    "        \n",
    "#             valid_epoch_loss = running_loss / len(dataset_split['val'])\n",
    "#             valid_epoch_acc = running_corrects / len(dataset_split['val']) * 100.\n",
    "#             F1_score = f1_score(all_labels, all_preds, average='macro')\n",
    "            \n",
    "#         # 학습 과정 중에 결과 출력\n",
    "#         print('#{} Loss: {:.4f} Acc: {:.4f}% Time: {:.4f}s'.format(epoch, epoch_loss, epoch_acc, time.time() - start_time))\n",
    "#         print(f'Valid Loss: {valid_epoch_loss:.4f} Valid Acc: {valid_epoch_acc:.4f} F1 Score: {F1_score:.4f}')\n",
    "# #         if F1_score > 0.77 and target == 'age' : break\n",
    "#         if F1_score > best_F1_score : best_F1_score, best_model = F1_score, copy.deepcopy(model)   ############최고모델 활용을 위한 코드 추가\n",
    "#         print('best_F1_score : ',best_F1_score) ############최고모델 활용을 위한 코드 추가\n",
    "        \n",
    "#     if ground_best_F1_score < best_F1_score : ############최고모델 활용을 위한 코드 추가\n",
    "#         print(f\"ground_best_F1_score갱신! {ground_best_F1_score} -> {best_F1_score}\")\n",
    "#         now = datetime.datetime.now()\n",
    "#         nowDatetime = now.strftime('%Y_%m%d_%H%M')\n",
    "#         torch.save(best_model.state_dict(), os.getcwd()+'/'+f'model_age_{nowDatetime}') ############최고모델 활용을 위한 코드 추가\n",
    "        \n",
    "        \n",
    "#     image_dir = os.path.join(test_dir, 'images')\n",
    "    \n",
    "#     image_paths = [os.path.join(image_dir, img_id) for img_id in sub_df.ImageID]\n",
    "    \n",
    "#     test_set = TestDatasetAge(image_paths, transforms, submission)  ###################################데이터셋 변경\n",
    "    \n",
    "#     test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False, num_workers=4)\n",
    "    \n",
    "#     all_predictions = []\n",
    "\n",
    "#     best_model.eval()\n",
    "#     all_output = []        ###########################################################\n",
    "#     with torch.no_grad():\n",
    "# #         for inputs in tqdm(test_dataloader):\n",
    "\n",
    "#         for inputs, features in tqdm(test_dataloader):\n",
    "\n",
    "#             inputs = inputs.to(device) \n",
    "#             features = features.to(device) ##################features 활용하는 부분 추가\n",
    "            \n",
    "# #             outputs = model(inputs)\n",
    "#             outputs = best_model(inputs,features)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "#             all_predictions.extend(preds.cpu().numpy())\n",
    "#             all_output.append(outputs)   #############################################\n",
    "#     mask_soft = torch.nn.functional.softmax(torch.cat(all_output,dim=0),dim=1)  ######\n",
    "#     for i in range(len(class_names)):  ###############################################\n",
    "#         sub_df[class_names[i]] = mask_soft[:,i].cpu().numpy()  #######################\n",
    "#     sub_df.to_csv(f'sub_age.csv')  ###################################################\n",
    "#     all_predictions2 = []\n",
    "\n",
    "#     for p in all_predictions:\n",
    "#         all_predictions2.append(class_names[p])\n",
    "        \n",
    "#     sub_df['age'] = all_predictions2\n",
    "    \n",
    "#     return sub_df.copy(), max(ground_best_F1_score,best_F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b63fc25-a586-4b74-aadd-6c50b13ba4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****start epoch****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:02<00:00,  5.17it/s]\n",
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.4904 Acc: 78.2891% Time: 65.4957s\n",
      "Valid Loss: 0.7043 Valid Acc: 73.8889 F1 Score: 0.6628\n",
      "best_F1_score :  0.6627686157616021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:01<00:00,  5.25it/s]\n",
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Loss: 0.2863 Acc: 87.7908% Time: 130.0870s\n",
      "Valid Loss: 1.0418 Valid Acc: 69.8148 F1 Score: 0.5819\n",
      "best_F1_score :  0.6627686157616021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n",
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#2 Loss: 0.2069 Acc: 91.4042% Time: 194.4426s\n",
      "Valid Loss: 0.9183 Valid Acc: 73.1018 F1 Score: 0.6398\n",
      "best_F1_score :  0.6627686157616021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:01<00:00,  5.28it/s]\n",
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#3 Loss: 0.1644 Acc: 92.9895% Time: 258.7118s\n",
      "Valid Loss: 1.4469 Valid Acc: 69.2593 F1 Score: 0.5642\n",
      "best_F1_score :  0.6627686157616021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:01<00:00,  5.26it/s]\n",
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4 Loss: 0.1217 Acc: 94.9043% Time: 323.1698s\n",
      "Valid Loss: 1.3952 Valid Acc: 68.9352 F1 Score: 0.5541\n",
      "best_F1_score :  0.6627686157616021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:01<00:00,  5.26it/s]\n",
      "  0%|          | 0/323 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5 Loss: 0.0897 Acc: 96.2477% Time: 387.6764s\n",
      "Valid Loss: 0.8374 Valid Acc: 77.8704 F1 Score: 0.7238\n",
      "best_F1_score :  0.7238224238831882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 323/323 [01:01<00:00,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6 Loss: 0.0780 Acc: 96.7830% Time: 452.0649s\n",
      "Valid Loss: 1.3250 Valid Acc: 73.8889 F1 Score: 0.6753\n",
      "best_F1_score :  0.7238224238831882\n",
      "ground_best_F1_score갱신! 0 -> 0.7238224238831882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:14<00:00, 13.87it/s]\n"
     ]
    }
   ],
   "source": [
    "submission_after_age, ground_best_F1_score = age_model_run(submission, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1cfc94-081c-4b39-b8ac-8cf97c5c521f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffff = submission_after_age.astype({'age':'int','gender':'int','mask':'int'})\n",
    "try : ffff['ans'] = ffff['mask'] + ffff['gender'] + ffff['age'] ; ffff = ffff.drop(['mask','gender','age'],axis=1)\n",
    "except : pass\n",
    "ffff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "419d1d98-3da0-40ae-913c-58757461490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "nowDatetime = now.strftime('%m%d_%H%M')\n",
    "ffff.to_csv(f'sub{nowDatetime}_AgeF1-{ground_best_F1_score:.4f}_epo2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ca825-cffd-4a21-aa47-3c5cd0ed0175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
